{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5697e15-d3f4-4e1d-a3d8-b6e1931cd6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Submission for Week 4 (Function 7):\n",
      "[0.0832023 , 0.32354808, 0.15089491, 0.27558739, 0.41362356, 0.26930961]\n",
      "Predicted Output: 0.2909 (std: 0.2082)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# 1. Prepare the Data (Function 7, Index 6)\n",
    "# Inputs from Week 1, 2, 3\n",
    "X_train = np.array([\n",
    "    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0],                         # Week 1\n",
    "    [0.2, 0.2, 0.2, 0.2, 0.2, 0.2],                         # Week 2\n",
    "    [0.213787, 0.185417, 0.205796, 0.191078, 0.174785, 0.191819] # Week 3\n",
    "])\n",
    "\n",
    "# Outputs from Week 1, 2, 3\n",
    "y_train = np.array([\n",
    "    3.408539273427753e-05,\n",
    "    0.4081092157295297,\n",
    "    0.34688512628942264\n",
    "])\n",
    "\n",
    "# 2. Define the Kernel\n",
    "# Matern kernel is generally better for physical functions than RBF.\n",
    "# WhiteKernel handles noise in the observations.\n",
    "kernel = ConstantKernel(1.0) * Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=1e-5)\n",
    "\n",
    "# 3. Fit the Gaussian Process\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "gp.fit(X_train, y_train)\n",
    "\n",
    "# 4. Define Acquisition Function (Upper Confidence Bound)\n",
    "# We want to maximize the function. UCB = mu + kappa * sigma\n",
    "def acquisition_func(x):\n",
    "    x = x.reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    kappa = 1.96  # Exploration/Exploitation balance parameter\n",
    "    return -(mean + kappa * std) # Negate because scipy minimizes\n",
    "\n",
    "# 5. Optimize to find the next input\n",
    "# We start the search around the best point found so far (Week 2's 0.2)\n",
    "best_x_so_far = X_train[np.argmax(y_train)]\n",
    "bounds = [(0.01, 1.0)] * 6  # Constraint: Positive numbers only\n",
    "\n",
    "res = minimize(\n",
    "    acquisition_func, \n",
    "    x0=best_x_so_far, \n",
    "    bounds=bounds, \n",
    "    method='L-BFGS-B'\n",
    ")\n",
    "\n",
    "# 6. Result\n",
    "next_input = res.x\n",
    "print(\"Recommended Submission for Week 4 (Function 7):\")\n",
    "print(np.array2string(next_input, separator=', '))\n",
    "\n",
    "# Optional: Predict expected value for this input\n",
    "pred_mean, pred_std = gp.predict(next_input.reshape(1, -1), return_std=True)\n",
    "print(f\"Predicted Output: {pred_mean[0]:.4f} (std: {pred_std[0]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0aac95c-01b5-4d07-83ca-a49de0ea7de9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
