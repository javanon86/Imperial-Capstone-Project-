{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b920428a-f768-487c-ae10-fcb8a8bcab5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "INDIVIDUAL ML MODEL CODE - ALL 8 FUNCTIONS\n",
      "====================================================================================================\n",
      "\n",
      "====================================================================================================\n",
      "F1 (2D) - LOCAL EXPLORATION AROUND BREAKTHROUGH\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "# F1: Week 6 found first non-zero at [0.45, 0.45] → 0.0128\n",
      "# Strategy: Explore nearby region\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "# Training data (6 weeks)\n",
      "X_f1 = np.array([\n",
      "    [0.10, 0.10],  # Week 1: 0.0\n",
      "    [0.12, 0.08],  # Week 2: 0.0\n",
      "    [0.21, 0.11],  # Week 3: 0.0\n",
      "    [0.14, 0.14],  # Week 4: 0.0\n",
      "    [0.08, 0.08],  # Week 5: 0.0\n",
      "    [0.45, 0.45]   # Week 6: 0.0128 ← BREAKTHROUGH!\n",
      "])\n",
      "y_f1 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0128])\n",
      "\n",
      "# Week 6 found signal at [0.45, 0.45]\n",
      "# Week 7: Explore nearby in positive gradient direction\n",
      "breakthrough_point = np.array([0.45, 0.45])\n",
      "\n",
      "# Test nearby points (gradient ascent)\n",
      "candidates = [\n",
      "    breakthrough_point + np.array([0.03, 0.03]),  # [0.48, 0.48]\n",
      "    breakthrough_point + np.array([0.05, 0.00]),  # [0.50, 0.45]\n",
      "    breakthrough_point + np.array([0.00, 0.05]),  # [0.45, 0.50]\n",
      "]\n",
      "\n",
      "# Choose: [0.48, 0.48] - symmetric increase\n",
      "week7_f1 = np.array([0.48, 0.48])\n",
      "\n",
      "print(\"Week 7 input:\", week7_f1)\n",
      "print(\"Strategy: Local gradient ascent from breakthrough\")\n",
      "\n",
      "Week 7 input: [0.48 0.48]\n",
      "Strategy: Local gradient ascent from breakthrough\n",
      "\n",
      "====================================================================================================\n",
      "F2 (2D) - GP WITH EXPLOITATION\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor\n",
      "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
      "\n",
      "# Training data (6 weeks)\n",
      "X_f2 = np.array([\n",
      "    [0.10, 0.10],   # Week 1: 0.0892 (previous best)\n",
      "    [0.12, 0.08],   # Week 2: 0.0705\n",
      "    [0.21, 0.11],   # Week 3: 0.0295\n",
      "    [0.14, 0.14],   # Week 4: 0.0150\n",
      "    [0.08, 0.08],   # Week 5: 0.0463\n",
      "    [0.111, 0.100]  # Week 6: 0.1300 ← NEW BEST!\n",
      "])\n",
      "y_f2 = np.array([0.0892, 0.0705, 0.0295, 0.0150, 0.0463, 0.1300])\n",
      "\n",
      "# Known correlations (negative)\n",
      "correlations_f2 = np.array([-0.530, -0.649])\n",
      "\n",
      "# Build GP with ARD kernel (learns dimension importance)\n",
      "# Initialize length scales from correlations\n",
      "init_length_scales = 1.0 / (np.abs(correlations_f2) + 0.1)\n",
      "\n",
      "kernel = ConstantKernel(1.0) * Matern(\n",
      "    length_scale=init_length_scales,\n",
      "    length_scale_bounds=(1e-2, 10.0),\n",
      "    nu=2.5\n",
      ")\n",
      "\n",
      "gp_f2 = GaussianProcessRegressor(\n",
      "    kernel=kernel,\n",
      "    n_restarts_optimizer=20,\n",
      "    alpha=1e-6,\n",
      "    normalize_y=True\n",
      ")\n",
      "gp_f2.fit(X_f2, y_f2)\n",
      "\n",
      "# Exploitation: Find maximum of GP mean\n",
      "best_so_far = X_f2[-1]  # Week 6 best\n",
      "\n",
      "# Generate candidates around best point\n",
      "n_candidates = 100\n",
      "candidates = []\n",
      "for i in range(n_candidates):\n",
      "    # Sample near best, with negative correlation guidance\n",
      "    candidate = best_so_far.copy()\n",
      "    candidate[0] += np.random.uniform(-0.02, 0.02)  # Small variation\n",
      "    candidate[1] += np.random.uniform(-0.02, 0.02)\n",
      "    candidate = np.clip(candidate, 0.0, 1.0)\n",
      "    candidates.append(candidate)\n",
      "\n",
      "candidates = np.array(candidates)\n",
      "\n",
      "# Predict on all candidates\n",
      "predictions = gp_f2.predict(candidates)\n",
      "\n",
      "# Choose best predicted\n",
      "best_idx = np.argmax(predictions)\n",
      "week7_f2 = candidates[best_idx]\n",
      "\n",
      "print(\"Week 7 input:\", week7_f2)\n",
      "print(\"Predicted output:\", predictions[best_idx])\n",
      "print(\"Learned length scales:\", gp_f2.kernel_.k2.length_scale)\n",
      "\n",
      "Week 7 input: [0.11148659 0.10103623]\n",
      "Predicted output: 0.12969409560674397\n",
      "Learned length scales: [0.01128657 0.01047978]\n",
      "\n",
      "====================================================================================================\n",
      "F3 (3D) - GP WITH EXPECTED IMPROVEMENT\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor\n",
      "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
      "from scipy.stats import norm\n",
      "\n",
      "# Training data (6 weeks)\n",
      "X_f3 = np.array([\n",
      "    [0.80, 0.80, 0.80],           # Week 1: -0.1055\n",
      "    [0.95, 0.95, 0.95],           # Week 2: -0.0919\n",
      "    [0.98, 0.99, 0.87],           # Week 3: -0.0856\n",
      "    [0.948885, 0.965632, 0.808397],  # Week 4: -0.0786 (best)\n",
      "    [1.01, 1.01, 0.82],           # Week 5: -1.1543 (penalty)\n",
      "    [0.928, 0.832, 0.004]         # Week 6: -0.1161 (ML fail)\n",
      "])\n",
      "y_f3 = np.array([-0.1055, -0.0919, -0.0856, -0.0786, -1.1543, -0.1161])\n",
      "\n",
      "# Known correlations\n",
      "correlations_f3 = np.array([-0.14, -0.23, -0.35])\n",
      "\n",
      "# Build GP\n",
      "init_length_scales = 1.0 / (np.abs(correlations_f3) + 0.1)\n",
      "\n",
      "kernel = ConstantKernel(1.0) * Matern(\n",
      "    length_scale=init_length_scales,\n",
      "    length_scale_bounds=(1e-2, 10.0),\n",
      "    nu=2.5\n",
      ")\n",
      "\n",
      "gp_f3 = GaussianProcessRegressor(\n",
      "    kernel=kernel,\n",
      "    n_restarts_optimizer=20,\n",
      "    alpha=1e-6,\n",
      "    normalize_y=True\n",
      ")\n",
      "gp_f3.fit(X_f3, y_f3)\n",
      "\n",
      "# Expected Improvement acquisition function\n",
      "def expected_improvement(X, gp, y_train, xi=0.01):\n",
      "    X = np.atleast_2d(X)\n",
      "    mu, sigma = gp.predict(X, return_std=True)\n",
      "    \n",
      "    best_y = np.max(y_train)\n",
      "    \n",
      "    with np.errstate(divide='warn'):\n",
      "        imp = mu - best_y - xi\n",
      "        Z = imp / sigma\n",
      "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
      "        ei[sigma == 0.0] = 0.0\n",
      "    \n",
      "    return ei\n",
      "\n",
      "# Generate candidates near Week 4 best (avoid Week 6 mistake)\n",
      "best_known = X_f3[3]  # Week 4\n",
      "n_candidates = 200\n",
      "\n",
      "candidates = []\n",
      "for i in range(n_candidates):\n",
      "    candidate = best_known.copy()\n",
      "    candidate += np.random.uniform(-0.1, 0.1, size=3)\n",
      "    candidate = np.clip(candidate, 0.0, 1.0)\n",
      "    candidates.append(candidate)\n",
      "\n",
      "candidates = np.array(candidates)\n",
      "\n",
      "# Compute EI for all candidates\n",
      "ei_scores = expected_improvement(candidates, gp_f3, y_f3)\n",
      "\n",
      "# Choose highest EI\n",
      "best_idx = np.argmax(ei_scores)\n",
      "week7_f3 = candidates[best_idx]\n",
      "\n",
      "print(\"Week 7 input:\", week7_f3)\n",
      "mu, std = gp_f3.predict([week7_f3], return_std=True)\n",
      "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
      "print(\"Learned length scales:\", gp_f3.kernel_.k2.length_scale)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 2 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 7 input: [0.85081639 0.9979837  0.84245168]\n",
      "Predicted output: -0.2615574073025218 ± 0.4288432038939278\n",
      "Learned length scales: [ 0.02016223 10.         10.        ]\n",
      "\n",
      "====================================================================================================\n",
      "F4 (4D) - GP FOR RECOVERY\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor\n",
      "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
      "from scipy.stats import norm\n",
      "\n",
      "# Training data (6 weeks)\n",
      "X_f4 = np.array([\n",
      "    [0.5, 0.5, 0.5, 0.5],      # Week 1: -3.986 (BEST)\n",
      "    [0.3, 0.3, 0.3, 0.3],      # Week 2: -4.306\n",
      "    [0.44, 0.29, 0.35, 1.25],  # Week 3: -30.129 (disaster)\n",
      "    [0.51, 0.60, 0.57, 0.01],  # Week 4: -12.492\n",
      "    [0.66, 0.30, 0.30, 0.36],  # Week 5: -7.262\n",
      "    [0.2, 0.2, 0.95, 0.4]      # Week 6: -19.009 (exploration fail)\n",
      "])\n",
      "y_f4 = np.array([-3.986, -4.306, -30.129, -12.492, -7.262, -19.009])\n",
      "\n",
      "# Known correlations\n",
      "correlations_f4 = np.array([-0.47, -0.37, -0.36, -0.77])\n",
      "\n",
      "# Build GP\n",
      "init_length_scales = 1.0 / (np.abs(correlations_f4) + 0.1)\n",
      "\n",
      "kernel = ConstantKernel(1.0) * Matern(\n",
      "    length_scale=init_length_scales,\n",
      "    length_scale_bounds=(1e-2, 10.0),\n",
      "    nu=2.5\n",
      ")\n",
      "\n",
      "gp_f4 = GaussianProcessRegressor(\n",
      "    kernel=kernel,\n",
      "    n_restarts_optimizer=20,\n",
      "    alpha=1e-6,\n",
      "    normalize_y=True\n",
      ")\n",
      "gp_f4.fit(X_f4, y_f4)\n",
      "\n",
      "# Expected Improvement for recovery\n",
      "def expected_improvement(X, gp, y_train, xi=0.01):\n",
      "    X = np.atleast_2d(X)\n",
      "    mu, sigma = gp.predict(X, return_std=True)\n",
      "    \n",
      "    best_y = np.max(y_train)\n",
      "    \n",
      "    with np.errstate(divide='warn'):\n",
      "        imp = mu - best_y - xi\n",
      "        Z = imp / sigma\n",
      "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
      "        ei[sigma == 0.0] = 0.0\n",
      "    \n",
      "    return ei\n",
      "\n",
      "# Generate candidates near center (Week 1 best)\n",
      "center = np.array([0.5, 0.5, 0.5, 0.5])\n",
      "n_candidates = 200\n",
      "\n",
      "candidates = []\n",
      "for i in range(n_candidates):\n",
      "    # Stay close to center\n",
      "    candidate = center + np.random.uniform(-0.1, 0.1, size=4)\n",
      "    candidate = np.clip(candidate, 0.0, 1.0)\n",
      "    candidates.append(candidate)\n",
      "\n",
      "candidates = np.array(candidates)\n",
      "\n",
      "# Compute EI\n",
      "ei_scores = expected_improvement(candidates, gp_f4, y_f4)\n",
      "\n",
      "# Choose highest EI\n",
      "best_idx = np.argmax(ei_scores)\n",
      "week7_f4 = candidates[best_idx]\n",
      "\n",
      "print(\"Week 7 input:\", week7_f4)\n",
      "mu, std = gp_f4.predict([week7_f4], return_std=True)\n",
      "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
      "print(\"Learned length scales:\", gp_f4.kernel_.k2.length_scale)\n",
      "print(\"Dimension importance: Dim 3 (54.6%), Dim 4 (37.7%)\")\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 7 input: [0.41157815 0.45830684 0.49380738 0.40190182]\n",
      "Predicted output: -3.8093973332416677 ± 3.416270626533292\n",
      "Learned length scales: [ 1.68369264 10.          0.20421943  0.29546285]\n",
      "Dimension importance: Dim 3 (54.6%), Dim 4 (37.7%)\n",
      "\n",
      "====================================================================================================\n",
      "F5 (4D) - GP WITH LOCAL SEARCH (CRITICAL!)\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor\n",
      "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
      "from scipy.optimize import minimize\n",
      "\n",
      "# Training data (6 weeks)\n",
      "X_f5 = np.array([\n",
      "    [0.3, 0.3, 0.3, 0.3],         # Week 1: 136.85\n",
      "    [0.28, 0.32, 0.3, 0.29],      # Week 2: 137.29\n",
      "    [0.344822, 0.264687, 0.374156, 0.203902],  # Week 3: 131.78\n",
      "    [0.196828, 0.320017, 0.3, 0.289958],       # Week 4: 140.74\n",
      "    [0.99, 0.9, 0.98, 0.93],      # Week 5: 5549.45 ← HUGE JUMP!\n",
      "    [0.985, 0.905, 0.975, 0.925]  # Week 6: 5398.58 (slight regression)\n",
      "])\n",
      "y_f5 = np.array([136.85, 137.29, 131.78, 140.74, 5549.45, 5398.58])\n",
      "\n",
      "# Known correlations (ALL very strong positive)\n",
      "correlations_f5 = np.array([0.986, 0.997, 0.994, 0.992])\n",
      "\n",
      "# Build GP - THIS IS CRITICAL!\n",
      "# Week 5→6: tiny move (0.005) caused -151 point loss\n",
      "# This indicates VERY sharp peak\n",
      "init_length_scales = 1.0 / (np.abs(correlations_f5) + 0.1)\n",
      "\n",
      "kernel = ConstantKernel(1.0) * Matern(\n",
      "    length_scale=init_length_scales,\n",
      "    length_scale_bounds=(1e-2, 10.0),\n",
      "    nu=2.5\n",
      ")\n",
      "\n",
      "gp_f5 = GaussianProcessRegressor(\n",
      "    kernel=kernel,\n",
      "    n_restarts_optimizer=20,\n",
      "    alpha=1e-6,\n",
      "    normalize_y=True\n",
      ")\n",
      "gp_f5.fit(X_f5, y_f5)\n",
      "\n",
      "# Local search from Week 5 best\n",
      "week5_best = np.array([0.99, 0.9, 0.98, 0.93])\n",
      "\n",
      "# Optimize GP mean prediction\n",
      "def objective(x):\n",
      "    return -gp_f5.predict([x])[0]\n",
      "\n",
      "# Use L-BFGS-B for gradient-based optimization\n",
      "result = minimize(\n",
      "    objective,\n",
      "    week5_best,\n",
      "    bounds=[(0.0, 1.0)] * 4,\n",
      "    method='L-BFGS-B'\n",
      ")\n",
      "\n",
      "week7_f5 = result.x\n",
      "\n",
      "print(\"Week 7 input:\", week7_f5)\n",
      "mu, std = gp_f5.predict([week7_f5], return_std=True)\n",
      "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
      "print(\"Improvement over Week 5 best:\", mu[0] - 5549.45)\n",
      "print()\n",
      "print(\"Learned length scales:\", gp_f5.kernel_.k2.length_scale)\n",
      "print(\"Key insight: Dim 3 (96.6% importance)\")\n",
      "print()\n",
      "print(\"Changes from Week 5 best:\")\n",
      "print(\"  Dim 1: 0.99 → {:.3f} ({:+.3f})\".format(week7_f5[0], week7_f5[0] - 0.99))\n",
      "print(\"  Dim 2: 0.90 → {:.3f} ({:+.3f})\".format(week7_f5[1], week7_f5[1] - 0.90))\n",
      "print(\"  Dim 3: 0.98 → {:.3f} ({:+.3f})\".format(week7_f5[2], week7_f5[2] - 0.98))\n",
      "print(\"  Dim 4: 0.93 → {:.3f} ({:+.3f})\".format(week7_f5[3], week7_f5[3] - 0.93))\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 7 input: [1.         0.85299463 1.         0.97702163]\n",
      "Predicted output: 6000.983127255267 ± 146.823197974517\n",
      "Improvement over Week 5 best: 451.5331272552676\n",
      "\n",
      "Learned length scales: [10.         10.          0.11669408 10.        ]\n",
      "Key insight: Dim 3 (96.6% importance)\n",
      "\n",
      "Changes from Week 5 best:\n",
      "  Dim 1: 0.99 → 1.000 (+0.010)\n",
      "  Dim 2: 0.90 → 0.853 (-0.047)\n",
      "  Dim 3: 0.98 → 1.000 (+0.020)\n",
      "  Dim 4: 0.93 → 0.977 (+0.047)\n",
      "\n",
      "====================================================================================================\n",
      "F6 (5D) - GP WITH EXPECTED IMPROVEMENT\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor\n",
      "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
      "from scipy.stats import norm\n",
      "\n",
      "# Training data (6 weeks)\n",
      "X_f6 = np.array([\n",
      "    [0.75, 0.75, 0.75, 0.75, 0.75],  # Week 1: -1.521\n",
      "    [0.3, 0.3, 0.3, 0.3, 0.3],       # Week 2: -1.139\n",
      "    [0.49, 0.02, 0.45, 0.40, 0.32],  # Week 3: -1.123\n",
      "    [0.69, 0.001, 0.04, 0.001, 0.001],  # Week 4: -2.067\n",
      "    [0.26, 0.18, 0.50, 0.48, 0.41],  # Week 5: -1.092 (BEST)\n",
      "    [0.1, 0.1, 0.7, 0.7, 0.6]        # Week 6: -1.231 (overshot)\n",
      "])\n",
      "y_f6 = np.array([-1.521, -1.139, -1.123, -2.067, -1.092, -1.231])\n",
      "\n",
      "# Known correlations\n",
      "correlations_f6 = np.array([-0.77, -0.54, 0.38, 0.42, 0.35])\n",
      "\n",
      "# Build GP\n",
      "init_length_scales = 1.0 / (np.abs(correlations_f6) + 0.1)\n",
      "\n",
      "kernel = ConstantKernel(1.0) * Matern(\n",
      "    length_scale=init_length_scales,\n",
      "    length_scale_bounds=(1e-2, 10.0),\n",
      "    nu=2.5\n",
      ")\n",
      "\n",
      "gp_f6 = GaussianProcessRegressor(\n",
      "    kernel=kernel,\n",
      "    n_restarts_optimizer=20,\n",
      "    alpha=1e-6,\n",
      "    normalize_y=True\n",
      ")\n",
      "gp_f6.fit(X_f6, y_f6)\n",
      "\n",
      "# Expected Improvement\n",
      "def expected_improvement(X, gp, y_train, xi=0.01):\n",
      "    X = np.atleast_2d(X)\n",
      "    mu, sigma = gp.predict(X, return_std=True)\n",
      "    \n",
      "    best_y = np.max(y_train)\n",
      "    \n",
      "    with np.errstate(divide='warn'):\n",
      "        imp = mu - best_y - xi\n",
      "        Z = imp / sigma\n",
      "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
      "        ei[sigma == 0.0] = 0.0\n",
      "    \n",
      "    return ei\n",
      "\n",
      "# Generate candidates near Week 5 best\n",
      "week5_best = np.array([0.26, 0.18, 0.50, 0.48, 0.41])\n",
      "n_candidates = 200\n",
      "\n",
      "candidates = []\n",
      "for i in range(n_candidates):\n",
      "    # Use correlation guidance\n",
      "    candidate = week5_best.copy()\n",
      "    candidate[0] -= np.random.uniform(0, 0.1)  # Dim 1: negative corr\n",
      "    candidate[1] -= np.random.uniform(0, 0.1)  # Dim 2: negative corr\n",
      "    candidate[2] += np.random.uniform(0, 0.2)  # Dim 3: positive corr\n",
      "    candidate[3] += np.random.uniform(0, 0.2)  # Dim 4: positive corr\n",
      "    candidate[4] += np.random.uniform(0, 0.15) # Dim 5: positive corr\n",
      "    candidate = np.clip(candidate, 0.0, 1.0)\n",
      "    candidates.append(candidate)\n",
      "\n",
      "candidates = np.array(candidates)\n",
      "\n",
      "# Compute EI\n",
      "ei_scores = expected_improvement(candidates, gp_f6, y_f6)\n",
      "\n",
      "# Choose highest EI\n",
      "best_idx = np.argmax(ei_scores)\n",
      "week7_f6 = candidates[best_idx]\n",
      "\n",
      "print(\"Week 7 input:\", week7_f6)\n",
      "mu, std = gp_f6.predict([week7_f6], return_std=True)\n",
      "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
      "print(\"Learned length scales:\", gp_f6.kernel_.k2.length_scale)\n",
      "print(\"Key insight: Dim 5 (89.2% importance)\")\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 2 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 7 input: [0.20245658 0.11563142 0.67536571 0.67009724 0.48254256]\n",
      "Predicted output: -1.1154870647741975 ± 0.04271793974705279\n",
      "Learned length scales: [10.         10.         10.         10.          0.30164874]\n",
      "Key insight: Dim 5 (89.2% importance)\n",
      "\n",
      "====================================================================================================\n",
      "F7 (6D) - GP WITH EXPLOITATION (PEER INFORMED)\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor\n",
      "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
      "\n",
      "# Training data (6 weeks)\n",
      "X_f7 = np.array([\n",
      "    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0],    # Week 1: 0.000034\n",
      "    [0.2, 0.2, 0.2, 0.2, 0.2, 0.2],    # Week 2: 0.408\n",
      "    [0.21, 0.19, 0.21, 0.19, 0.17, 0.19],  # Week 3: 0.347\n",
      "    [0.08, 0.32, 0.15, 0.28, 0.41, 0.27],  # Week 4: 0.568\n",
      "    [0.05, 0.50, 0.25, 0.20, 0.15, 0.85],  # Week 5: 0.836\n",
      "    [0.06, 0.48, 0.25, 0.2, 0.4, 0.75]     # Week 6: 1.435 ← HUGE WIN!\n",
      "])\n",
      "y_f7 = np.array([0.000034, 0.408, 0.347, 0.568, 0.836, 1.435])\n",
      "\n",
      "# Known correlations\n",
      "correlations_f7 = np.array([-0.88, -0.50, -0.76, -0.77, -0.76, -0.15])\n",
      "\n",
      "# Peer gradients (dimension importance from peer's analysis)\n",
      "peer_gradients = np.array([0.12, 0.45, 0.08, 0.52, 0.23, 0.15])\n",
      "\n",
      "# Build GP\n",
      "init_length_scales = 1.0 / (np.abs(correlations_f7) + 0.1)\n",
      "\n",
      "kernel = ConstantKernel(1.0) * Matern(\n",
      "    length_scale=init_length_scales,\n",
      "    length_scale_bounds=(1e-2, 10.0),\n",
      "    nu=2.5\n",
      ")\n",
      "\n",
      "gp_f7 = GaussianProcessRegressor(\n",
      "    kernel=kernel,\n",
      "    n_restarts_optimizer=20,\n",
      "    alpha=1e-6,\n",
      "    normalize_y=True\n",
      ")\n",
      "gp_f7.fit(X_f7, y_f7)\n",
      "\n",
      "# Exploitation: maximize GP mean near Week 6 success\n",
      "week6_best = np.array([0.06, 0.48, 0.25, 0.2, 0.4, 0.75])\n",
      "n_candidates = 200\n",
      "\n",
      "candidates = []\n",
      "for i in range(n_candidates):\n",
      "    # Small variations around Week 6\n",
      "    candidate = week6_best.copy()\n",
      "    candidate += np.random.uniform(-0.05, 0.05, size=6)\n",
      "    candidate = np.clip(candidate, 0.0, 1.0)\n",
      "    candidates.append(candidate)\n",
      "\n",
      "candidates = np.array(candidates)\n",
      "\n",
      "# Predict on all candidates\n",
      "predictions = gp_f7.predict(candidates)\n",
      "\n",
      "# Choose best predicted\n",
      "best_idx = np.argmax(predictions)\n",
      "week7_f7 = candidates[best_idx]\n",
      "\n",
      "print(\"Week 7 input:\", week7_f7)\n",
      "mu, std = gp_f7.predict([week7_f7], return_std=True)\n",
      "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
      "print(\"Improvement over Week 6:\", mu[0] - 1.435)\n",
      "print()\n",
      "print(\"Learned length scales:\", gp_f7.kernel_.k2.length_scale)\n",
      "print(\"Key insight: Dim 6 (94% importance)\")\n",
      "print()\n",
      "print(\"Comparison with peer's winning pattern:\")\n",
      "print(\"  Peer: [0.058, 0.492, 0.247, 0.218, 0.420, 0.731] → 1.365\")\n",
      "print(\"  Us (Week 6): [0.060, 0.480, 0.250, 0.200, 0.400, 0.750] → 1.435\")\n",
      "print(\"  Us (Week 7):\", week7_f7)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 2 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Week 7 input: [0.03375881 0.46354552 0.24328114 0.18587307 0.41966973 0.734308  ]\n",
      "Predicted output: 1.449608010933372 ± 0.07021635072502484\n",
      "Improvement over Week 6: 0.01460801093337194\n",
      "\n",
      "Learned length scales: [10.         10.         10.         10.         10.          0.12661705]\n",
      "Key insight: Dim 6 (94% importance)\n",
      "\n",
      "Comparison with peer's winning pattern:\n",
      "  Peer: [0.058, 0.492, 0.247, 0.218, 0.420, 0.731] → 1.365\n",
      "  Us (Week 6): [0.060, 0.480, 0.250, 0.200, 0.400, 0.750] → 1.435\n",
      "  Us (Week 7): [0.03375881 0.46354552 0.24328114 0.18587307 0.41966973 0.734308  ]\n",
      "\n",
      "====================================================================================================\n",
      "F8 (8D) - GP WITH EXPECTED IMPROVEMENT\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "import numpy as np\n",
      "from sklearn.gaussian_process import GaussianProcessRegressor\n",
      "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
      "from scipy.stats import norm\n",
      "\n",
      "# Training data (6 weeks)\n",
      "X_f8 = np.array([\n",
      "    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],  # Week 1: 9.542\n",
      "    [0.12, 0.09, 0.11, 0.1, 0.08, 0.13, 0.11, 0.09],  # Week 2: 9.554\n",
      "    [0.29, 0.25, 0.02, 0.29, 0.14, 0.22, 0.25, 0.30],  # Week 3: 9.548\n",
      "    [1.0, 0.001, 1.0, 0.001, 0.001, 1.0, 1.0, 0.001],  # Week 4: 4.180 (disaster)\n",
      "    [0.05, 0.25, 0.25, 0.25, 0.25, 0.25, 0.05, 0.05],  # Week 5: 9.643\n",
      "    [0.18, 0.15, 0.2, 0.15, 0.25, 0.15, 0.15, 0.18]    # Week 6: 9.676 (best)\n",
      "])\n",
      "y_f8 = np.array([9.542, 9.554, 9.548, 4.180, 9.643, 9.676])\n",
      "\n",
      "# Known correlations\n",
      "correlations_f8 = np.array([-0.98, 0.73, -0.98, 0.70, 0.72, -0.97, -0.98, 0.52])\n",
      "\n",
      "# Build GP\n",
      "init_length_scales = 1.0 / (np.abs(correlations_f8) + 0.1)\n",
      "\n",
      "kernel = ConstantKernel(1.0) * Matern(\n",
      "    length_scale=init_length_scales,\n",
      "    length_scale_bounds=(1e-2, 10.0),\n",
      "    nu=2.5\n",
      ")\n",
      "\n",
      "gp_f8 = GaussianProcessRegressor(\n",
      "    kernel=kernel,\n",
      "    n_restarts_optimizer=20,\n",
      "    alpha=1e-6,\n",
      "    normalize_y=True\n",
      ")\n",
      "gp_f8.fit(X_f8, y_f8)\n",
      "\n",
      "# Expected Improvement\n",
      "def expected_improvement(X, gp, y_train, xi=0.01):\n",
      "    X = np.atleast_2d(X)\n",
      "    mu, sigma = gp.predict(X, return_std=True)\n",
      "    \n",
      "    best_y = np.max(y_train)\n",
      "    \n",
      "    with np.errstate(divide='warn'):\n",
      "        imp = mu - best_y - xi\n",
      "        Z = imp / sigma\n",
      "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
      "        ei[sigma == 0.0] = 0.0\n",
      "    \n",
      "    return ei\n",
      "\n",
      "# Generate candidates near Week 6 best (avoid extremes like Week 4)\n",
      "week6_best = np.array([0.18, 0.15, 0.2, 0.15, 0.25, 0.15, 0.15, 0.18])\n",
      "n_candidates = 200\n",
      "\n",
      "candidates = []\n",
      "for i in range(n_candidates):\n",
      "    # Small perturbations, prioritize Dim 3 and 5\n",
      "    candidate = week6_best.copy()\n",
      "    candidate += np.random.uniform(-0.05, 0.05, size=8)\n",
      "    # Keep away from extremes (0 or 1)\n",
      "    candidate = np.clip(candidate, 0.05, 0.95)\n",
      "    candidates.append(candidate)\n",
      "\n",
      "candidates = np.array(candidates)\n",
      "\n",
      "# Compute EI\n",
      "ei_scores = expected_improvement(candidates, gp_f8, y_f8)\n",
      "\n",
      "# Choose highest EI\n",
      "best_idx = np.argmax(ei_scores)\n",
      "week7_f8 = candidates[best_idx]\n",
      "\n",
      "print(\"Week 7 input:\", week7_f8)\n",
      "mu, std = gp_f8.predict([week7_f8], return_std=True)\n",
      "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
      "print(\"Learned length scales:\", gp_f8.kernel_.k2.length_scale)\n",
      "print(\"Key insight: Dim 3 (71.4% importance)\")\n",
      "print(\"Peer insight: Dims 3, 5 most important\")\n",
      "\n",
      "Week 7 input: [0.18454302 0.11535902 0.24846594 0.13876248 0.25273906 0.19278705\n",
      " 0.18786876 0.19312925]\n",
      "Predicted output: 9.661046897523937 ± 0.06545931352730916\n",
      "Learned length scales: [10.         10.          0.57108516 10.         10.         10.\n",
      " 10.         10.        ]\n",
      "Key insight: Dim 3 (71.4% importance)\n",
      "Peer insight: Dims 3, 5 most important\n",
      "\n",
      "====================================================================================================\n",
      "SUMMARY - ALL 8 MODELS\n",
      "====================================================================================================\n",
      "\n",
      "\n",
      "F1: Local exploration (no GP needed, just gradient ascent)\n",
      "F2: GP + Exploitation (maximize mean prediction)\n",
      "F3: GP + Expected Improvement (balanced exploration)\n",
      "F4: GP + Expected Improvement (recovery near center)\n",
      "F5: GP + Local Search (gradient descent on GP mean) ⭐ CRITICAL\n",
      "F6: GP + Expected Improvement (correlation-guided)\n",
      "F7: GP + Exploitation (build on Week 6 success)\n",
      "F8: GP + Expected Improvement (avoid extremes)\n",
      "\n",
      "ALL models use:\n",
      "  • Matern kernel (nu=2.5) for flexibility\n",
      "  • ARD (Automatic Relevance Determination) - learns dimension importance\n",
      "  • Correlation initialization for length scales\n",
      "  • 20 optimizer restarts for robustness\n",
      "  • Output normalization for stability\n",
      "\n",
      "Key Strategies:\n",
      "  • Exploit when winning (F2, F7)\n",
      "  • Explore when uncertain (F3, F8)\n",
      "  • Recover when failing (F4, F6)\n",
      "  • Local search for sharp peaks (F5)\n",
      "\n",
      "====================================================================================================\n",
      "ALL MODEL CODE COMPLETE!\n",
      "====================================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 1 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 3 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 4 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 5 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 6 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\andre\\anaconda3\\Lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:452: ConvergenceWarning: The optimal value found for dimension 7 of parameter k2__length_scale is close to the specified upper bound 10.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "INDIVIDUAL ML MODEL CODE FOR EACH FUNCTION\n",
    "Clean, runnable code showing exactly how each Week 7 input was generated\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel, Matern\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"INDIVIDUAL ML MODEL CODE - ALL 8 FUNCTIONS\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# F1 - LOCAL EXPLORATION (No Complex Model)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"F1 (2D) - LOCAL EXPLORATION AROUND BREAKTHROUGH\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "code_f1 = '''\n",
    "# F1: Week 6 found first non-zero at [0.45, 0.45] → 0.0128\n",
    "# Strategy: Explore nearby region\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Training data (6 weeks)\n",
    "X_f1 = np.array([\n",
    "    [0.10, 0.10],  # Week 1: 0.0\n",
    "    [0.12, 0.08],  # Week 2: 0.0\n",
    "    [0.21, 0.11],  # Week 3: 0.0\n",
    "    [0.14, 0.14],  # Week 4: 0.0\n",
    "    [0.08, 0.08],  # Week 5: 0.0\n",
    "    [0.45, 0.45]   # Week 6: 0.0128 ← BREAKTHROUGH!\n",
    "])\n",
    "y_f1 = np.array([0.0, 0.0, 0.0, 0.0, 0.0, 0.0128])\n",
    "\n",
    "# Week 6 found signal at [0.45, 0.45]\n",
    "# Week 7: Explore nearby in positive gradient direction\n",
    "breakthrough_point = np.array([0.45, 0.45])\n",
    "\n",
    "# Test nearby points (gradient ascent)\n",
    "candidates = [\n",
    "    breakthrough_point + np.array([0.03, 0.03]),  # [0.48, 0.48]\n",
    "    breakthrough_point + np.array([0.05, 0.00]),  # [0.50, 0.45]\n",
    "    breakthrough_point + np.array([0.00, 0.05]),  # [0.45, 0.50]\n",
    "]\n",
    "\n",
    "# Choose: [0.48, 0.48] - symmetric increase\n",
    "week7_f1 = np.array([0.48, 0.48])\n",
    "\n",
    "print(\"Week 7 input:\", week7_f1)\n",
    "print(\"Strategy: Local gradient ascent from breakthrough\")\n",
    "'''\n",
    "\n",
    "print(code_f1)\n",
    "exec(code_f1)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# F2 - GAUSSIAN PROCESS WITH EXPLOITATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"F2 (2D) - GP WITH EXPLOITATION\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "code_f2 = '''\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
    "\n",
    "# Training data (6 weeks)\n",
    "X_f2 = np.array([\n",
    "    [0.10, 0.10],   # Week 1: 0.0892 (previous best)\n",
    "    [0.12, 0.08],   # Week 2: 0.0705\n",
    "    [0.21, 0.11],   # Week 3: 0.0295\n",
    "    [0.14, 0.14],   # Week 4: 0.0150\n",
    "    [0.08, 0.08],   # Week 5: 0.0463\n",
    "    [0.111, 0.100]  # Week 6: 0.1300 ← NEW BEST!\n",
    "])\n",
    "y_f2 = np.array([0.0892, 0.0705, 0.0295, 0.0150, 0.0463, 0.1300])\n",
    "\n",
    "# Known correlations (negative)\n",
    "correlations_f2 = np.array([-0.530, -0.649])\n",
    "\n",
    "# Build GP with ARD kernel (learns dimension importance)\n",
    "# Initialize length scales from correlations\n",
    "init_length_scales = 1.0 / (np.abs(correlations_f2) + 0.1)\n",
    "\n",
    "kernel = ConstantKernel(1.0) * Matern(\n",
    "    length_scale=init_length_scales,\n",
    "    length_scale_bounds=(1e-2, 10.0),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp_f2 = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_f2.fit(X_f2, y_f2)\n",
    "\n",
    "# Exploitation: Find maximum of GP mean\n",
    "best_so_far = X_f2[-1]  # Week 6 best\n",
    "\n",
    "# Generate candidates around best point\n",
    "n_candidates = 100\n",
    "candidates = []\n",
    "for i in range(n_candidates):\n",
    "    # Sample near best, with negative correlation guidance\n",
    "    candidate = best_so_far.copy()\n",
    "    candidate[0] += np.random.uniform(-0.02, 0.02)  # Small variation\n",
    "    candidate[1] += np.random.uniform(-0.02, 0.02)\n",
    "    candidate = np.clip(candidate, 0.0, 1.0)\n",
    "    candidates.append(candidate)\n",
    "\n",
    "candidates = np.array(candidates)\n",
    "\n",
    "# Predict on all candidates\n",
    "predictions = gp_f2.predict(candidates)\n",
    "\n",
    "# Choose best predicted\n",
    "best_idx = np.argmax(predictions)\n",
    "week7_f2 = candidates[best_idx]\n",
    "\n",
    "print(\"Week 7 input:\", week7_f2)\n",
    "print(\"Predicted output:\", predictions[best_idx])\n",
    "print(\"Learned length scales:\", gp_f2.kernel_.k2.length_scale)\n",
    "'''\n",
    "\n",
    "print(code_f2)\n",
    "exec(code_f2)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# F3 - GP WITH BALANCED EXPLORATION\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"F3 (3D) - GP WITH EXPECTED IMPROVEMENT\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "code_f3 = '''\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Training data (6 weeks)\n",
    "X_f3 = np.array([\n",
    "    [0.80, 0.80, 0.80],           # Week 1: -0.1055\n",
    "    [0.95, 0.95, 0.95],           # Week 2: -0.0919\n",
    "    [0.98, 0.99, 0.87],           # Week 3: -0.0856\n",
    "    [0.948885, 0.965632, 0.808397],  # Week 4: -0.0786 (best)\n",
    "    [1.01, 1.01, 0.82],           # Week 5: -1.1543 (penalty)\n",
    "    [0.928, 0.832, 0.004]         # Week 6: -0.1161 (ML fail)\n",
    "])\n",
    "y_f3 = np.array([-0.1055, -0.0919, -0.0856, -0.0786, -1.1543, -0.1161])\n",
    "\n",
    "# Known correlations\n",
    "correlations_f3 = np.array([-0.14, -0.23, -0.35])\n",
    "\n",
    "# Build GP\n",
    "init_length_scales = 1.0 / (np.abs(correlations_f3) + 0.1)\n",
    "\n",
    "kernel = ConstantKernel(1.0) * Matern(\n",
    "    length_scale=init_length_scales,\n",
    "    length_scale_bounds=(1e-2, 10.0),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp_f3 = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_f3.fit(X_f3, y_f3)\n",
    "\n",
    "# Expected Improvement acquisition function\n",
    "def expected_improvement(X, gp, y_train, xi=0.01):\n",
    "    X = np.atleast_2d(X)\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    \n",
    "    best_y = np.max(y_train)\n",
    "    \n",
    "    with np.errstate(divide='warn'):\n",
    "        imp = mu - best_y - xi\n",
    "        Z = imp / sigma\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "    \n",
    "    return ei\n",
    "\n",
    "# Generate candidates near Week 4 best (avoid Week 6 mistake)\n",
    "best_known = X_f3[3]  # Week 4\n",
    "n_candidates = 200\n",
    "\n",
    "candidates = []\n",
    "for i in range(n_candidates):\n",
    "    candidate = best_known.copy()\n",
    "    candidate += np.random.uniform(-0.1, 0.1, size=3)\n",
    "    candidate = np.clip(candidate, 0.0, 1.0)\n",
    "    candidates.append(candidate)\n",
    "\n",
    "candidates = np.array(candidates)\n",
    "\n",
    "# Compute EI for all candidates\n",
    "ei_scores = expected_improvement(candidates, gp_f3, y_f3)\n",
    "\n",
    "# Choose highest EI\n",
    "best_idx = np.argmax(ei_scores)\n",
    "week7_f3 = candidates[best_idx]\n",
    "\n",
    "print(\"Week 7 input:\", week7_f3)\n",
    "mu, std = gp_f3.predict([week7_f3], return_std=True)\n",
    "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
    "print(\"Learned length scales:\", gp_f3.kernel_.k2.length_scale)\n",
    "'''\n",
    "\n",
    "print(code_f3)\n",
    "exec(code_f3)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# F4 - GP WITH RECOVERY (CENTERED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"F4 (4D) - GP FOR RECOVERY\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "code_f4 = '''\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Training data (6 weeks)\n",
    "X_f4 = np.array([\n",
    "    [0.5, 0.5, 0.5, 0.5],      # Week 1: -3.986 (BEST)\n",
    "    [0.3, 0.3, 0.3, 0.3],      # Week 2: -4.306\n",
    "    [0.44, 0.29, 0.35, 1.25],  # Week 3: -30.129 (disaster)\n",
    "    [0.51, 0.60, 0.57, 0.01],  # Week 4: -12.492\n",
    "    [0.66, 0.30, 0.30, 0.36],  # Week 5: -7.262\n",
    "    [0.2, 0.2, 0.95, 0.4]      # Week 6: -19.009 (exploration fail)\n",
    "])\n",
    "y_f4 = np.array([-3.986, -4.306, -30.129, -12.492, -7.262, -19.009])\n",
    "\n",
    "# Known correlations\n",
    "correlations_f4 = np.array([-0.47, -0.37, -0.36, -0.77])\n",
    "\n",
    "# Build GP\n",
    "init_length_scales = 1.0 / (np.abs(correlations_f4) + 0.1)\n",
    "\n",
    "kernel = ConstantKernel(1.0) * Matern(\n",
    "    length_scale=init_length_scales,\n",
    "    length_scale_bounds=(1e-2, 10.0),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp_f4 = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_f4.fit(X_f4, y_f4)\n",
    "\n",
    "# Expected Improvement for recovery\n",
    "def expected_improvement(X, gp, y_train, xi=0.01):\n",
    "    X = np.atleast_2d(X)\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    \n",
    "    best_y = np.max(y_train)\n",
    "    \n",
    "    with np.errstate(divide='warn'):\n",
    "        imp = mu - best_y - xi\n",
    "        Z = imp / sigma\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "    \n",
    "    return ei\n",
    "\n",
    "# Generate candidates near center (Week 1 best)\n",
    "center = np.array([0.5, 0.5, 0.5, 0.5])\n",
    "n_candidates = 200\n",
    "\n",
    "candidates = []\n",
    "for i in range(n_candidates):\n",
    "    # Stay close to center\n",
    "    candidate = center + np.random.uniform(-0.1, 0.1, size=4)\n",
    "    candidate = np.clip(candidate, 0.0, 1.0)\n",
    "    candidates.append(candidate)\n",
    "\n",
    "candidates = np.array(candidates)\n",
    "\n",
    "# Compute EI\n",
    "ei_scores = expected_improvement(candidates, gp_f4, y_f4)\n",
    "\n",
    "# Choose highest EI\n",
    "best_idx = np.argmax(ei_scores)\n",
    "week7_f4 = candidates[best_idx]\n",
    "\n",
    "print(\"Week 7 input:\", week7_f4)\n",
    "mu, std = gp_f4.predict([week7_f4], return_std=True)\n",
    "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
    "print(\"Learned length scales:\", gp_f4.kernel_.k2.length_scale)\n",
    "print(\"Dimension importance: Dim 3 (54.6%), Dim 4 (37.7%)\")\n",
    "'''\n",
    "\n",
    "print(code_f4)\n",
    "exec(code_f4)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# F5 - GP WITH LOCAL SEARCH (SHARP PEAK)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"F5 (4D) - GP WITH LOCAL SEARCH (CRITICAL!)\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "code_f5 = '''\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Training data (6 weeks)\n",
    "X_f5 = np.array([\n",
    "    [0.3, 0.3, 0.3, 0.3],         # Week 1: 136.85\n",
    "    [0.28, 0.32, 0.3, 0.29],      # Week 2: 137.29\n",
    "    [0.344822, 0.264687, 0.374156, 0.203902],  # Week 3: 131.78\n",
    "    [0.196828, 0.320017, 0.3, 0.289958],       # Week 4: 140.74\n",
    "    [0.99, 0.9, 0.98, 0.93],      # Week 5: 5549.45 ← HUGE JUMP!\n",
    "    [0.985, 0.905, 0.975, 0.925]  # Week 6: 5398.58 (slight regression)\n",
    "])\n",
    "y_f5 = np.array([136.85, 137.29, 131.78, 140.74, 5549.45, 5398.58])\n",
    "\n",
    "# Known correlations (ALL very strong positive)\n",
    "correlations_f5 = np.array([0.986, 0.997, 0.994, 0.992])\n",
    "\n",
    "# Build GP - THIS IS CRITICAL!\n",
    "# Week 5→6: tiny move (0.005) caused -151 point loss\n",
    "# This indicates VERY sharp peak\n",
    "init_length_scales = 1.0 / (np.abs(correlations_f5) + 0.1)\n",
    "\n",
    "kernel = ConstantKernel(1.0) * Matern(\n",
    "    length_scale=init_length_scales,\n",
    "    length_scale_bounds=(1e-2, 10.0),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp_f5 = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_f5.fit(X_f5, y_f5)\n",
    "\n",
    "# Local search from Week 5 best\n",
    "week5_best = np.array([0.99, 0.9, 0.98, 0.93])\n",
    "\n",
    "# Optimize GP mean prediction\n",
    "def objective(x):\n",
    "    return -gp_f5.predict([x])[0]\n",
    "\n",
    "# Use L-BFGS-B for gradient-based optimization\n",
    "result = minimize(\n",
    "    objective,\n",
    "    week5_best,\n",
    "    bounds=[(0.0, 1.0)] * 4,\n",
    "    method='L-BFGS-B'\n",
    ")\n",
    "\n",
    "week7_f5 = result.x\n",
    "\n",
    "print(\"Week 7 input:\", week7_f5)\n",
    "mu, std = gp_f5.predict([week7_f5], return_std=True)\n",
    "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
    "print(\"Improvement over Week 5 best:\", mu[0] - 5549.45)\n",
    "print()\n",
    "print(\"Learned length scales:\", gp_f5.kernel_.k2.length_scale)\n",
    "print(\"Key insight: Dim 3 (96.6% importance)\")\n",
    "print()\n",
    "print(\"Changes from Week 5 best:\")\n",
    "print(\"  Dim 1: 0.99 → {:.3f} ({:+.3f})\".format(week7_f5[0], week7_f5[0] - 0.99))\n",
    "print(\"  Dim 2: 0.90 → {:.3f} ({:+.3f})\".format(week7_f5[1], week7_f5[1] - 0.90))\n",
    "print(\"  Dim 3: 0.98 → {:.3f} ({:+.3f})\".format(week7_f5[2], week7_f5[2] - 0.98))\n",
    "print(\"  Dim 4: 0.93 → {:.3f} ({:+.3f})\".format(week7_f5[3], week7_f5[3] - 0.93))\n",
    "'''\n",
    "\n",
    "print(code_f5)\n",
    "exec(code_f5)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# F6 - GP WITH BALANCED EI\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"F6 (5D) - GP WITH EXPECTED IMPROVEMENT\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "code_f6 = '''\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Training data (6 weeks)\n",
    "X_f6 = np.array([\n",
    "    [0.75, 0.75, 0.75, 0.75, 0.75],  # Week 1: -1.521\n",
    "    [0.3, 0.3, 0.3, 0.3, 0.3],       # Week 2: -1.139\n",
    "    [0.49, 0.02, 0.45, 0.40, 0.32],  # Week 3: -1.123\n",
    "    [0.69, 0.001, 0.04, 0.001, 0.001],  # Week 4: -2.067\n",
    "    [0.26, 0.18, 0.50, 0.48, 0.41],  # Week 5: -1.092 (BEST)\n",
    "    [0.1, 0.1, 0.7, 0.7, 0.6]        # Week 6: -1.231 (overshot)\n",
    "])\n",
    "y_f6 = np.array([-1.521, -1.139, -1.123, -2.067, -1.092, -1.231])\n",
    "\n",
    "# Known correlations\n",
    "correlations_f6 = np.array([-0.77, -0.54, 0.38, 0.42, 0.35])\n",
    "\n",
    "# Build GP\n",
    "init_length_scales = 1.0 / (np.abs(correlations_f6) + 0.1)\n",
    "\n",
    "kernel = ConstantKernel(1.0) * Matern(\n",
    "    length_scale=init_length_scales,\n",
    "    length_scale_bounds=(1e-2, 10.0),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp_f6 = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_f6.fit(X_f6, y_f6)\n",
    "\n",
    "# Expected Improvement\n",
    "def expected_improvement(X, gp, y_train, xi=0.01):\n",
    "    X = np.atleast_2d(X)\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    \n",
    "    best_y = np.max(y_train)\n",
    "    \n",
    "    with np.errstate(divide='warn'):\n",
    "        imp = mu - best_y - xi\n",
    "        Z = imp / sigma\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "    \n",
    "    return ei\n",
    "\n",
    "# Generate candidates near Week 5 best\n",
    "week5_best = np.array([0.26, 0.18, 0.50, 0.48, 0.41])\n",
    "n_candidates = 200\n",
    "\n",
    "candidates = []\n",
    "for i in range(n_candidates):\n",
    "    # Use correlation guidance\n",
    "    candidate = week5_best.copy()\n",
    "    candidate[0] -= np.random.uniform(0, 0.1)  # Dim 1: negative corr\n",
    "    candidate[1] -= np.random.uniform(0, 0.1)  # Dim 2: negative corr\n",
    "    candidate[2] += np.random.uniform(0, 0.2)  # Dim 3: positive corr\n",
    "    candidate[3] += np.random.uniform(0, 0.2)  # Dim 4: positive corr\n",
    "    candidate[4] += np.random.uniform(0, 0.15) # Dim 5: positive corr\n",
    "    candidate = np.clip(candidate, 0.0, 1.0)\n",
    "    candidates.append(candidate)\n",
    "\n",
    "candidates = np.array(candidates)\n",
    "\n",
    "# Compute EI\n",
    "ei_scores = expected_improvement(candidates, gp_f6, y_f6)\n",
    "\n",
    "# Choose highest EI\n",
    "best_idx = np.argmax(ei_scores)\n",
    "week7_f6 = candidates[best_idx]\n",
    "\n",
    "print(\"Week 7 input:\", week7_f6)\n",
    "mu, std = gp_f6.predict([week7_f6], return_std=True)\n",
    "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
    "print(\"Learned length scales:\", gp_f6.kernel_.k2.length_scale)\n",
    "print(\"Key insight: Dim 5 (89.2% importance)\")\n",
    "'''\n",
    "\n",
    "print(code_f6)\n",
    "exec(code_f6)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# F7 - GP WITH EXPLOITATION (PEER PATTERN)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"F7 (6D) - GP WITH EXPLOITATION (PEER INFORMED)\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "code_f7 = '''\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
    "\n",
    "# Training data (6 weeks)\n",
    "X_f7 = np.array([\n",
    "    [1.0, 1.0, 1.0, 1.0, 1.0, 1.0],    # Week 1: 0.000034\n",
    "    [0.2, 0.2, 0.2, 0.2, 0.2, 0.2],    # Week 2: 0.408\n",
    "    [0.21, 0.19, 0.21, 0.19, 0.17, 0.19],  # Week 3: 0.347\n",
    "    [0.08, 0.32, 0.15, 0.28, 0.41, 0.27],  # Week 4: 0.568\n",
    "    [0.05, 0.50, 0.25, 0.20, 0.15, 0.85],  # Week 5: 0.836\n",
    "    [0.06, 0.48, 0.25, 0.2, 0.4, 0.75]     # Week 6: 1.435 ← HUGE WIN!\n",
    "])\n",
    "y_f7 = np.array([0.000034, 0.408, 0.347, 0.568, 0.836, 1.435])\n",
    "\n",
    "# Known correlations\n",
    "correlations_f7 = np.array([-0.88, -0.50, -0.76, -0.77, -0.76, -0.15])\n",
    "\n",
    "# Peer gradients (dimension importance from peer's analysis)\n",
    "peer_gradients = np.array([0.12, 0.45, 0.08, 0.52, 0.23, 0.15])\n",
    "\n",
    "# Build GP\n",
    "init_length_scales = 1.0 / (np.abs(correlations_f7) + 0.1)\n",
    "\n",
    "kernel = ConstantKernel(1.0) * Matern(\n",
    "    length_scale=init_length_scales,\n",
    "    length_scale_bounds=(1e-2, 10.0),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp_f7 = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_f7.fit(X_f7, y_f7)\n",
    "\n",
    "# Exploitation: maximize GP mean near Week 6 success\n",
    "week6_best = np.array([0.06, 0.48, 0.25, 0.2, 0.4, 0.75])\n",
    "n_candidates = 200\n",
    "\n",
    "candidates = []\n",
    "for i in range(n_candidates):\n",
    "    # Small variations around Week 6\n",
    "    candidate = week6_best.copy()\n",
    "    candidate += np.random.uniform(-0.05, 0.05, size=6)\n",
    "    candidate = np.clip(candidate, 0.0, 1.0)\n",
    "    candidates.append(candidate)\n",
    "\n",
    "candidates = np.array(candidates)\n",
    "\n",
    "# Predict on all candidates\n",
    "predictions = gp_f7.predict(candidates)\n",
    "\n",
    "# Choose best predicted\n",
    "best_idx = np.argmax(predictions)\n",
    "week7_f7 = candidates[best_idx]\n",
    "\n",
    "print(\"Week 7 input:\", week7_f7)\n",
    "mu, std = gp_f7.predict([week7_f7], return_std=True)\n",
    "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
    "print(\"Improvement over Week 6:\", mu[0] - 1.435)\n",
    "print()\n",
    "print(\"Learned length scales:\", gp_f7.kernel_.k2.length_scale)\n",
    "print(\"Key insight: Dim 6 (94% importance)\")\n",
    "print()\n",
    "print(\"Comparison with peer's winning pattern:\")\n",
    "print(\"  Peer: [0.058, 0.492, 0.247, 0.218, 0.420, 0.731] → 1.365\")\n",
    "print(\"  Us (Week 6): [0.060, 0.480, 0.250, 0.200, 0.400, 0.750] → 1.435\")\n",
    "print(\"  Us (Week 7):\", week7_f7)\n",
    "'''\n",
    "\n",
    "print(code_f7)\n",
    "exec(code_f7)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# F8 - GP WITH BALANCED EI\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"F8 (8D) - GP WITH EXPECTED IMPROVEMENT\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "code_f8 = '''\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, ConstantKernel\n",
    "from scipy.stats import norm\n",
    "\n",
    "# Training data (6 weeks)\n",
    "X_f8 = np.array([\n",
    "    [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1],  # Week 1: 9.542\n",
    "    [0.12, 0.09, 0.11, 0.1, 0.08, 0.13, 0.11, 0.09],  # Week 2: 9.554\n",
    "    [0.29, 0.25, 0.02, 0.29, 0.14, 0.22, 0.25, 0.30],  # Week 3: 9.548\n",
    "    [1.0, 0.001, 1.0, 0.001, 0.001, 1.0, 1.0, 0.001],  # Week 4: 4.180 (disaster)\n",
    "    [0.05, 0.25, 0.25, 0.25, 0.25, 0.25, 0.05, 0.05],  # Week 5: 9.643\n",
    "    [0.18, 0.15, 0.2, 0.15, 0.25, 0.15, 0.15, 0.18]    # Week 6: 9.676 (best)\n",
    "])\n",
    "y_f8 = np.array([9.542, 9.554, 9.548, 4.180, 9.643, 9.676])\n",
    "\n",
    "# Known correlations\n",
    "correlations_f8 = np.array([-0.98, 0.73, -0.98, 0.70, 0.72, -0.97, -0.98, 0.52])\n",
    "\n",
    "# Build GP\n",
    "init_length_scales = 1.0 / (np.abs(correlations_f8) + 0.1)\n",
    "\n",
    "kernel = ConstantKernel(1.0) * Matern(\n",
    "    length_scale=init_length_scales,\n",
    "    length_scale_bounds=(1e-2, 10.0),\n",
    "    nu=2.5\n",
    ")\n",
    "\n",
    "gp_f8 = GaussianProcessRegressor(\n",
    "    kernel=kernel,\n",
    "    n_restarts_optimizer=20,\n",
    "    alpha=1e-6,\n",
    "    normalize_y=True\n",
    ")\n",
    "gp_f8.fit(X_f8, y_f8)\n",
    "\n",
    "# Expected Improvement\n",
    "def expected_improvement(X, gp, y_train, xi=0.01):\n",
    "    X = np.atleast_2d(X)\n",
    "    mu, sigma = gp.predict(X, return_std=True)\n",
    "    \n",
    "    best_y = np.max(y_train)\n",
    "    \n",
    "    with np.errstate(divide='warn'):\n",
    "        imp = mu - best_y - xi\n",
    "        Z = imp / sigma\n",
    "        ei = imp * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "        ei[sigma == 0.0] = 0.0\n",
    "    \n",
    "    return ei\n",
    "\n",
    "# Generate candidates near Week 6 best (avoid extremes like Week 4)\n",
    "week6_best = np.array([0.18, 0.15, 0.2, 0.15, 0.25, 0.15, 0.15, 0.18])\n",
    "n_candidates = 200\n",
    "\n",
    "candidates = []\n",
    "for i in range(n_candidates):\n",
    "    # Small perturbations, prioritize Dim 3 and 5\n",
    "    candidate = week6_best.copy()\n",
    "    candidate += np.random.uniform(-0.05, 0.05, size=8)\n",
    "    # Keep away from extremes (0 or 1)\n",
    "    candidate = np.clip(candidate, 0.05, 0.95)\n",
    "    candidates.append(candidate)\n",
    "\n",
    "candidates = np.array(candidates)\n",
    "\n",
    "# Compute EI\n",
    "ei_scores = expected_improvement(candidates, gp_f8, y_f8)\n",
    "\n",
    "# Choose highest EI\n",
    "best_idx = np.argmax(ei_scores)\n",
    "week7_f8 = candidates[best_idx]\n",
    "\n",
    "print(\"Week 7 input:\", week7_f8)\n",
    "mu, std = gp_f8.predict([week7_f8], return_std=True)\n",
    "print(\"Predicted output:\", mu[0], \"±\", std[0])\n",
    "print(\"Learned length scales:\", gp_f8.kernel_.k2.length_scale)\n",
    "print(\"Key insight: Dim 3 (71.4% importance)\")\n",
    "print(\"Peer insight: Dims 3, 5 most important\")\n",
    "'''\n",
    "\n",
    "print(code_f8)\n",
    "exec(code_f8)\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# Summary\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"SUMMARY - ALL 8 MODELS\")\n",
    "print(\"=\"*100)\n",
    "print()\n",
    "\n",
    "summary = \"\"\"\n",
    "F1: Local exploration (no GP needed, just gradient ascent)\n",
    "F2: GP + Exploitation (maximize mean prediction)\n",
    "F3: GP + Expected Improvement (balanced exploration)\n",
    "F4: GP + Expected Improvement (recovery near center)\n",
    "F5: GP + Local Search (gradient descent on GP mean) ⭐ CRITICAL\n",
    "F6: GP + Expected Improvement (correlation-guided)\n",
    "F7: GP + Exploitation (build on Week 6 success)\n",
    "F8: GP + Expected Improvement (avoid extremes)\n",
    "\n",
    "ALL models use:\n",
    "  • Matern kernel (nu=2.5) for flexibility\n",
    "  • ARD (Automatic Relevance Determination) - learns dimension importance\n",
    "  • Correlation initialization for length scales\n",
    "  • 20 optimizer restarts for robustness\n",
    "  • Output normalization for stability\n",
    "\n",
    "Key Strategies:\n",
    "  • Exploit when winning (F2, F7)\n",
    "  • Explore when uncertain (F3, F8)\n",
    "  • Recover when failing (F4, F6)\n",
    "  • Local search for sharp peaks (F5)\n",
    "\"\"\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"=\"*100)\n",
    "print(\"ALL MODEL CODE COMPLETE!\")\n",
    "print(\"=\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4051ce-f29f-460b-b1be-b80c6b128012",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
