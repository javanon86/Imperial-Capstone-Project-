{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81dade6f-51bb-476b-8118-fdd26f15c696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Week 4 Prediction ---\n",
      "Recommended Submission for Function 3: [1. 1. 1.]\n",
      "Predicted Value (Acquisition Score): 0.02522384969352018\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# 1. Historical Data for Function 3 (Index 2)\n",
    "# Extracted from the provided files for Weeks 1-3\n",
    "X = np.array([\n",
    "    [0.1, 0.1, 0.1],                 # Week 1\n",
    "    [0.2, 0.2, 0.2],                 # Week 2\n",
    "    [0.123105, 0.025252, 0.134332],\n",
    "    [0.94888554, 0.96563203, 0.80839735]\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    -0.09338622073872602,  # Week 1 Output\n",
    "    -0.16230936451166192,  # Week 2 Output\n",
    "    -0.1662102640375241,    # Week 3 Output\n",
    "    -0.07863721776440244\n",
    "])\n",
    "\n",
    "# 2. Train Gaussian Process\n",
    "# Matern kernel allows for non-linear relationships. \n",
    "# WhiteKernel handles potential noise in the observations.\n",
    "kernel = Matern(length_scale=1.0, nu=2.5) + WhiteKernel(noise_level=1e-5)\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "gp.fit(X, y)\n",
    "\n",
    "# 3. Define Acquisition Function (Upper Confidence Bound)\n",
    "# We balance maximizing the mean prediction with exploring high uncertainty (std).\n",
    "# kappa=2.576 corresponds to roughly 99% confidence exploration.\n",
    "def acq_func(x, gp, kappa=2.576):\n",
    "    x = x.reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    # We return negative because 'minimize' finds the lowest value\n",
    "    return -(mean + kappa * std)\n",
    "\n",
    "# 4. Optimize Next Submission\n",
    "# We search for inputs between 0 and 1 (positive numbers constraint).\n",
    "bounds = [(1e-6, 1.0)] * 3\n",
    "best_x = None\n",
    "best_val = np.inf\n",
    "\n",
    "# Run optimization from multiple random starting points to avoid local optima\n",
    "np.random.seed(42)\n",
    "for _ in range(50):\n",
    "    x0 = np.random.uniform(0, 1, 3)\n",
    "    res = minimize(acq_func, x0, args=(gp,), bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "print(\"--- Week 4 Prediction ---\")\n",
    "print(f\"Recommended Submission for Function 3: {best_x}\")\n",
    "print(f\"Predicted Value (Acquisition Score): {-best_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a33eb49-1427-4752-b30a-94b9c5feb330",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Week 5 Prediction ---\n",
      "Recommended Submission for Function 3: [26.0557643  40.92214319 23.80908706]\n",
      "Predicted Mean: 0.000000\n",
      "Predicted Std: 0.123949\n",
      "Acquisition Score (UCB): 0.319293\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, ConstantKernel\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# 1. Historical Data for Function 3 (Index 2)\n",
    "X = np.array([\n",
    "    [0.1, 0.1, 0.1],                 # Week 1\n",
    "    [0.2, 0.2, 0.2],                 # Week 2\n",
    "    [0.123105, 0.025252, 0.134332],  # Week 3\n",
    "    [0.94888554, 0.96563203, 0.80839735]  # Week 4\n",
    "])\n",
    "\n",
    "y = np.array([\n",
    "    -0.09338622073872602,  # Week 1 Output\n",
    "    -0.16230936451166192,  # Week 2 Output\n",
    "    -0.1662102640375241,   # Week 3 Output\n",
    "    -0.07863721776440244   # Week 4 Output\n",
    "])\n",
    "\n",
    "# 2. Train Gaussian Process\n",
    "# Use ConstantKernel to allow the GP to scale to any output magnitude\n",
    "# Matern kernel with adaptive length_scale_bounds for larger input domains\n",
    "kernel = ConstantKernel(1.0, constant_value_bounds=(1e-3, 1e3)) * \\\n",
    "         Matern(length_scale=1.0, length_scale_bounds=(1e-2, 1e2), nu=2.5) + \\\n",
    "         WhiteKernel(noise_level=1e-5, noise_level_bounds=(1e-10, 1e-1))\n",
    "\n",
    "gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10, random_state=42)\n",
    "gp.fit(X, y)\n",
    "\n",
    "# 3. Define Acquisition Function (Upper Confidence Bound)\n",
    "def acq_func(x, gp, kappa=2.576):\n",
    "    x = x.reshape(1, -1)\n",
    "    mean, std = gp.predict(x, return_std=True)\n",
    "    return -(mean + kappa * std)\n",
    "\n",
    "# 4. Optimize Next Submission\n",
    "# Set upper bound much higher - can be adjusted based on domain knowledge\n",
    "# Using 10.0 as a reasonable starting point, but can go higher\n",
    "UPPER_BOUND = 100.0  # Adjust this as needed (can be 100, 1000, etc.)\n",
    "\n",
    "bounds = [(1e-6, UPPER_BOUND)] * 3\n",
    "\n",
    "best_x = None\n",
    "best_val = np.inf\n",
    "\n",
    "# Run optimization from multiple random starting points\n",
    "np.random.seed(42)\n",
    "for _ in range(100):  # Increased iterations for larger search space\n",
    "    # Sample from a broader distribution\n",
    "    x0 = np.random.uniform(0, UPPER_BOUND, 3)\n",
    "    res = minimize(acq_func, x0, args=(gp,), bounds=bounds, method='L-BFGS-B')\n",
    "    if res.fun < best_val:\n",
    "        best_val = res.fun\n",
    "        best_x = res.x\n",
    "\n",
    "# Also try some points near existing best observations\n",
    "for x_observed in X:\n",
    "    # Explore around observed points with some scaling\n",
    "    for scale in [0.5, 1.0, 1.5, 2.0, 3.0]:\n",
    "        x0 = x_observed * scale\n",
    "        x0 = np.clip(x0, 1e-6, UPPER_BOUND)\n",
    "        res = minimize(acq_func, x0, args=(gp,), bounds=bounds, method='L-BFGS-B')\n",
    "        if res.fun < best_val:\n",
    "            best_val = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "print(\"--- Week 5 Prediction ---\")\n",
    "print(f\"Recommended Submission for Function 3: {best_x}\")\n",
    "print(f\"Predicted Mean: {gp.predict(best_x.reshape(1,-1))[0]:.6f}\")\n",
    "mean, std = gp.predict(best_x.reshape(1,-1), return_std=True)\n",
    "print(f\"Predicted Std: {std[0]:.6f}\")\n",
    "print(f\"Acquisition Score (UCB): {-best_val:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aa2ae8-2ac5-4f2b-b04e-a63a889224dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
