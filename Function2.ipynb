{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c36540a1-a720-4643-9095-df9c438be228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Coefficients: b (Sum)=6.5732, c (SumSq)=-23.3407\n",
      "Optimal single input x: 0.1408090196144389\n",
      "Recommended Submission for Function 2: array([0.1408090196144389, 0.1408090196144389])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Data for Function 2 from Weeks 1, 2, and 3\n",
    "# Extracted from inputs/outputs files\n",
    "X = np.array([\n",
    "    [0.1, 0.1],              # Week 1\n",
    "    [0.12, 0.08],            # Week 2\n",
    "    [0.21161, 0.111229]      # Week 3\n",
    "])\n",
    "y = np.array([\n",
    "    0.08918359070852336,     # Week 1 Output\n",
    "    0.0705110497571995,      # Week 2 Output\n",
    "    0.029501383191375512     # Week 3 Output\n",
    "])\n",
    "\n",
    "# Feature Engineering for Symmetric Quadratic Model\n",
    "# We assume the function is symmetric f(x1, x2) = f(x2, x1) and quadratic.\n",
    "# Features: Sum (x1+x2) and Sum of Squares (x1^2 + x2^2)\n",
    "# Model: y = Intercept + b * Sum + c * SumSq\n",
    "features = np.column_stack([\n",
    "    X[:, 0] + X[:, 1],        # Sum\n",
    "    X[:, 0]**2 + X[:, 1]**2   # Sum of Squares\n",
    "])\n",
    "\n",
    "# Fit Linear Regression to estimate parameters b and c\n",
    "model = LinearRegression()\n",
    "model.fit(features, y)\n",
    "\n",
    "# Extract coefficients\n",
    "# y = Intercept + b*(x1+x2) + c*(x1^2+x2^2)\n",
    "b = model.coef_[0]\n",
    "c = model.coef_[1]\n",
    "\n",
    "# To maximize y, we find where the derivative is zero.\n",
    "# Assuming symmetry x1 = x2 = x:\n",
    "# y(x) = Intercept + b*(2x) + c*(2x^2)\n",
    "# dy/dx = 2b + 4cx = 0\n",
    "# x = -2b / 4c = -b / (2c)\n",
    "\n",
    "optimal_x = -b / (2 * c)\n",
    "\n",
    "print(f\"Regression Coefficients: b (Sum)={b:.4f}, c (SumSq)={c:.4f}\")\n",
    "print(f\"Optimal single input x: {optimal_x}\")\n",
    "print(f\"Recommended Submission for Function 2: array([{optimal_x}, {optimal_x}])\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b6b82e-8fbe-478b-887b-f9978a25c1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
import numpy as np
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel
from scipy.optimize import minimize
 
# Training data (Weeks 1-4)
X_train = np.array([
    [0.1, 0.1],
    [0.12, 0.08],
    [0.21161, 0.111229],
    [0.140809, 0.140809]
])
y_train = np.array([0.0892, 0.0705, 0.0295, 0.0150])
 
# Train GP
kernel = ConstantKernel(1.0) * RBF(length_scale=0.05)
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)
gp.fit(X_train, y_train)
 
# Find maximum
def objective(x):
    return -gp.predict(x.reshape(1, -1))[0]
 
result = minimize(objective, x0=[0.1, 0.1], bounds=[(0.01, 0.3), (0.01, 0.3)])
 
print(f"Week 5 Prediction: {result.x}")
print(f"Expected output: {-result.fun:.6f}")
